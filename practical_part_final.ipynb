{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical part for the PDC project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions handling bit vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates a 78-character ASCII string at random.\n",
    "def generate_ascii_string():\n",
    "    return \"\".join([chr(int(np.random.rand()*127)) for i in range(0, 78)])\n",
    "\n",
    "# Performs a conversion from ASCII string to binary symbols\n",
    "def ascii_str_to_binary(ascii_str):\n",
    "    return str(''.join(format(ord(i), '08b')[1:] for i in ascii_str))\n",
    "\n",
    "# Performs the inverse conversion, from a binary stream to ASCII characters\n",
    "def binary_to_ascii_str(binstr):\n",
    "    byte_binstr = \"\".join(['0' + byte for byte in split_bit_str(binstr, 7)])\n",
    "    binary_int = int(byte_binstr, 2)\n",
    "    byte_number = (binary_int.bit_length() + 7) // 8\n",
    "    binary_array = binary_int.to_bytes(byte_number, \"big\")\n",
    "    return binary_array.decode()\n",
    "\n",
    "# Splits a bit string composed of 7-bit codewords into chunks of size 'chunk_size'.\n",
    "def split_bit_str(bit_str, chunk_size):\n",
    "    return [bit_str[i:i+chunk_size] for i in range(0, len(bit_str), chunk_size)]\n",
    "\n",
    "# Gets the whole alphabet from a codeword length\n",
    "def get_alphabet_from_codeword_length(length):\n",
    "    return [f'{i:0{length}b}' for i in range(0, 2**length)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoding criterion functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes the distance between a symbol and every point of a given constellation and returns the index of the nearest point in the constellation\n",
    "def minimum_distance_criterion(constellation, symbol):\n",
    "    return np.argmin([((symbol.real - point.real)**2 + (symbol.imag - point.imag)**2) for point in constellation])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging functions to check the encoding/decoding states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets every possible codeword lengths for which the length divides the total length of the original bitstring\n",
    "def compute_codeword_lengths(bit_str):\n",
    "    n = len(bit_str)\n",
    "    return [i for i in range(1, n+1) if n % i == 0]\n",
    "\n",
    "# Gets all the positions where bit_str1 is different from bit_str2 (bit_str1 and bit_str2 MUST HAVE THE SAME SIZE !)\n",
    "def get_diff_positions(bit_str1, bit_str2):\n",
    "    return [i for i in range(0, len(bit_str1)) if bit_str1[i] != bit_str2[i]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constellation-related functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### m-QAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes the PAM constellation for a given number of points and a distance for each of these points.\n",
    "def pam(n, d):\n",
    "    right_side = np.array([d*i + (d/2) for i in range(0, int(n/2))])\n",
    "    left_side = -right_side\n",
    "    return np.append(np.sort(left_side), right_side)\n",
    "\n",
    "# Computes the whole m-QAM constellation, to be used to map each codeword to a point generated here\n",
    "# WARNING: m MUST BE A POWER OF 2 HERE !!!\n",
    "def m_qam(m, d, max_energy = (3/2)):\n",
    "    if d > max_energy:\n",
    "        raise OverflowError(\"ERROR: the distance you have set is too big for the project.\")\n",
    "\n",
    "    # First we handle the weird configurations\n",
    "    if m == 2:\n",
    "        return pam(m, d)\n",
    "\n",
    "    elif m == 8:\n",
    "        real_axis_pam = pam(4, d)\n",
    "        imaginary_axis_pam = pam(2, d)\n",
    "        return np.array([[complex(re, im) for re in real_axis_pam] for im in imaginary_axis_pam]).flatten()\n",
    "\n",
    "    else:    \n",
    "        # First we take the square root of the QAM size, if it is an integer then we will generate a perfect square\n",
    "        # Otherwise, we try to find the nearest perfect square with sides of even lengths such that it contains more points than our desired constellation\n",
    "        axis_len = int(np.sqrt(m))\n",
    "\n",
    "        if axis_len**2 != m:\n",
    "             # We want axes containing an even number of points, and a bigger constellation than the one we requested in this case\n",
    "            if axis_len % 2 != 0:\n",
    "                axis_len += 1\n",
    "            else:\n",
    "                axis_len += 2\n",
    "\n",
    "        # We compute the difference between the number of points in the nearest perfect square and the number of points in our requested constellation\n",
    "        nb_points_to_delete = abs(m - axis_len**2)\n",
    "\n",
    "        # if the difference is positive => we need to remove 'diff_with_nearest_square' points from the nearest perfect square\n",
    "        # => we generate the perfect square before removing points inside it\n",
    "        real_axis_pam = pam(axis_len, d)\n",
    "        if real_axis_pam.max() > max_energy:\n",
    "            raise OverflowError(\"ERROR: You have some points that are outside the constrained square. Try to lower the distance or reduce the size of the constellation.\")\n",
    "        \n",
    "        imaginary_axis_pam = pam(axis_len, d)[::-1]\n",
    "        points_pairs = np.array([[complex(re, im) for re in real_axis_pam] for im in imaginary_axis_pam])\n",
    "\n",
    "        # Now that the constellation has been generated, if diff_with_nearest_square is not 0 we remove the additional points\n",
    "        if nb_points_to_delete > 0:\n",
    "            nb_points_to_remove_per_quarter = nb_points_to_delete / 4\n",
    "            nb_rows_to_affect_per_quarter = int(np.sqrt(nb_points_to_remove_per_quarter))\n",
    "\n",
    "            # If the square root isn't whole => we must re-organize the zones where to delete the points (they are not squares anymore)\n",
    "            difference_from_whole_square = nb_points_to_remove_per_quarter - nb_rows_to_affect_per_quarter**2\n",
    "\n",
    "            if difference_from_whole_square > 0:\n",
    "                nb_rows_to_affect_per_quarter = difference_from_whole_square\n",
    "                nb_points_to_remove_per_quarter_row = nb_points_to_remove_per_quarter / difference_from_whole_square\n",
    "            else:\n",
    "                nb_points_to_remove_per_quarter_row = nb_rows_to_affect_per_quarter\n",
    "\n",
    "            # First we set the points to delete to 0\n",
    "            for j in range(0, int(nb_rows_to_affect_per_quarter)):\n",
    "                for i in range(0, int(nb_points_to_remove_per_quarter_row)):\n",
    "                    points_pairs[j, i] = 0\n",
    "                    points_pairs[j, len(points_pairs[0])-1-i] = 0\n",
    "                    points_pairs[len(points_pairs[0])-1-j, i] = 0\n",
    "                    points_pairs[len(points_pairs[0])-1-j, len(points_pairs[0])-1-i] = 0\n",
    "\n",
    "        # We flatten the array to make it easier to map the codewords\n",
    "        points_pairs = points_pairs.flatten()\n",
    "\n",
    "        # Then, we remove all the points set to 0 (impossible to have if the dimension is a square with sides of even length, so no worries)\n",
    "        points_pairs = np.delete(points_pairs, np.argwhere(points_pairs == 0.0+0.0j))\n",
    "\n",
    "        return points_pairs\n",
    "\n",
    "# Gets the maximum distance for a given QAM configuration\n",
    "def get_max_qam_distance(m, tolerance, max_energy):\n",
    "    if m == 2:\n",
    "        pam_size = 2\n",
    "    elif m == 8:\n",
    "        pam_size = 4\n",
    "    else:\n",
    "        pam_size = int(np.sqrt(m))\n",
    "        if pam_size**2 != m:\n",
    "            # We want axes containing an even number of points, and a bigger constellation than the one we requested in this case\n",
    "            if pam_size % 2 != 0:\n",
    "                pam_size += 1\n",
    "            else:\n",
    "                pam_size += 2\n",
    "\n",
    "    max_distance = 0.0\n",
    "    for d in np.arange(0, max_energy, tolerance):\n",
    "        real_axis_pam = pam(pam_size, d)\n",
    "        if real_axis_pam.max() <= max_energy:\n",
    "            max_distance = d\n",
    "        else:\n",
    "            return max_distance\n",
    "    return max_distance\n",
    "    \n",
    "\n",
    "# Performs the QAM encoding (in a linear fashion for the moment => might be re-worked)\n",
    "def m_qam_encoder(codeword, constellation, alphabet, energy_per_symbol=0):\n",
    "    try:\n",
    "        k = alphabet.index(codeword)\n",
    "        m = len(alphabet)\n",
    "        return constellation[k]\n",
    "    except OverflowError as ovferr:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Server-related functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize_complex(complex_vector,file_name):\n",
    "    complex_vector = complex_vector.reshape(-1)\n",
    "    np.savetxt(file_name,np.concatenate([np.real(complex_vector),\n",
    "    np.imag(complex_vector)]))\n",
    "\n",
    "def deserialize_complex(file_name):\n",
    "    tx_data = np.loadtxt(file_name)\n",
    "    N_sample = tx_data.size\n",
    "    N_sample = N_sample//2\n",
    "    tx_data = tx_data[0:N_sample] + 1j*tx_data[N_sample:(2*N_sample)]\n",
    "    return tx_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encodes a string into a sequence of complex numbers & adds dummy points in front of it, given an encoder, a constellation, an alphabet and a number of dummy points\n",
    "def encode_string(raw_str, n_dummy_symbols, encoder, dummy_symbol, constellation = [], alphabet = []):\n",
    "    if n_dummy_symbols >= 100:\n",
    "        raise OverflowError(\"ERROR: The batch of dummy samples cannot be equal or exceed 100 symbols.\") \n",
    "    bit_str = ascii_str_to_binary(raw_str)\n",
    "    splitted_bit_str = split_bit_str(bit_str, int(np.log2(len(alphabet))))\n",
    "    splitted_bit_str_size = len(splitted_bit_str)\n",
    "    if splitted_bit_str_size > 100:\n",
    "        raise OverflowError(\"ERROR: The string without the dummy symbols cannot exceed 100 symbols.\") \n",
    "\n",
    "    if splitted_bit_str_size + n_dummy_symbols > 100:\n",
    "        raise OverflowError(f\"ERROR: the number of dummy samples is too high, the max value you can set here is {100 - splitted_bit_str_size}.\")\n",
    "            \n",
    "    theta_estimator_batch = np.full((n_dummy_symbols, 1), dummy_symbol)\n",
    "\n",
    "    return np.append(theta_estimator_batch, np.array([encoder(codeword=codeword, constellation=constellation, alphabet=alphabet) for codeword in splitted_bit_str]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decodes a bitstring outputted by the channel, given a constellation, an alphabet, a dummy symbol and the number of sent dummy symbols.\n",
    "\n",
    "def decode_str(noisy_str, dummy_symbol, n_dummy_symbols, alphabet, constellation):\n",
    "    # Isolate the dummy symbols to estimate the phase shift\n",
    "    dummy_symbols = noisy_str[0:n_dummy_symbols]\n",
    "    \n",
    "    # Estimate the phase shift (np.angle gives a value between (-pi, pi])\n",
    "    phase = (np.angle(np.sum(dummy_symbols)) + np.pi) - (np.angle(dummy_symbol) + np.pi) \n",
    "\n",
    "    # print(f\"Estimated phase: {phase}, phase with normalization: {phase % 2*np.pi}\")\n",
    "    # Apply the inverse phase shift to every codeword\n",
    "    dephased_symbols = np.exp(-1j * phase) * noisy_str[n_dummy_symbols:]\n",
    "\n",
    "    decoded_codewords = [alphabet[minimum_distance_criterion(constellation, symbol)] for symbol in dephased_symbols]\n",
    "    resulting_bit_str = \"\".join(decoded_codewords)\n",
    "    return resulting_bit_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting everything together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u000f?3v_m/\u0016\u00023\n",
      "[\f\u0012n\u0002{(n\u0006@FdrU\u0005+gO\u0016Yi'bOM\u0014RL\fED|r6m0'xq\u0002+hYAI\u0016vr\u001f9;X(\u0002n\n",
      "<T5MZCw\u000f\u000e\u0010\n"
     ]
    }
   ],
   "source": [
    "# The string to be processed\n",
    "str_to_process = generate_ascii_string() # TODO: CHANGE THE STRING WITH THE GIVEN ONE\n",
    "print(str_to_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invariant values (constraint)\n",
    "max_energy = 3/2\n",
    "dummy_symbol = max_energy + 1j * max_energy\n",
    "\n",
    "# FOR A 64-QAM\n",
    "codeword_size = 6 \n",
    "n_dummy_symbols = 4\n",
    "distance_margin = 0.0001\n",
    "encoder = m_qam_encoder\n",
    "\n",
    "# Generating the constellation & alphabet from codeword size\n",
    "constellation_size = 2**codeword_size\n",
    "distance = get_max_qam_distance(constellation_size, distance_margin, max_energy)\n",
    "constellation = m_qam(constellation_size, distance, max_energy)\n",
    "alphabet = get_alphabet_from_codeword_length(codeword_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the string\n",
    "encoded_str = encode_string(\n",
    "    str_to_process, \n",
    "    constellation=constellation, \n",
    "    alphabet=alphabet, \n",
    "    n_dummy_symbols=n_dummy_symbols, \n",
    "    dummy_symbol=dummy_symbol, \n",
    "    encoder=encoder\n",
    ")\n",
    "\n",
    "# Serializing the output to a text file to send it to the server\n",
    "serialize_complex(encoded_str, \"input.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Command for the server (with VPN) : python3 client/client.py --input_file=input.txt --output_file=output.txt --srv_hostname=iscsrv72.epfl.ch --srv_port=80\n",
    "\n",
    "(or if we use a conda environment: prefix the command by 'conda run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u000f?3v_m/\u0016\u00023\n",
      "[\f\u0012n\u0002{(n\u0006@FdrU\u0005+gO\u0016Yi'bOM\u0014RL\fED|r6m0'xq\u0002+hYAI\u0016vr\u001f9;X(\u0002n\n",
      "<T5MZCw\u000f\u000e\u0010\n",
      "Is perfectly decoded: True\n"
     ]
    }
   ],
   "source": [
    "# Extracting the noisy output from the generated file\n",
    "noisy_str = deserialize_complex(\"output.txt\")\n",
    "\n",
    "# Decoding the bit string\n",
    "decoded_bitstr = decode_str(\n",
    "    noisy_str, \n",
    "    dummy_symbol=dummy_symbol, \n",
    "    n_dummy_symbols=n_dummy_symbols, \n",
    "    alphabet=alphabet,\n",
    "    constellation=constellation\n",
    ")\n",
    "\n",
    "# Converting the bitstring into ASCII and printing it\n",
    "decoded_ascii = binary_to_ascii_str(decoded_bitstr)\n",
    "print(decoded_ascii)\n",
    "print(f\"Is perfectly decoded: {decoded_ascii == str_to_process}\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c6e4e9f98eb68ad3b7c296f83d20e6de614cb42e90992a65aa266555a3137d0d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
